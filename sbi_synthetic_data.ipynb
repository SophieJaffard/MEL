{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_simulator import *\n",
    "import torch\n",
    "from sbi.utils import BoxUniform\n",
    "from sbi.inference import SNPE_A\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create synthetic data to test the SBI method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dims = 2 #s and eta\n",
    "num_sims = 1000\n",
    "\n",
    "eta_inf = 0.09\n",
    "eta_sup = 2\n",
    "s_inf = 0.04\n",
    "s_sup = 0.2\n",
    "\n",
    "nb_obj_max = 100\n",
    "\n",
    "prior = BoxUniform(low=torch.tensor([eta_inf,s_inf]), high=torch.tensor([eta_sup,s_sup]))\n",
    "\n",
    "\n",
    "def simulator_sbi(theta):\n",
    "    \"\"\"\n",
    "    This function takes in argument the parameters theta and returns simulations of the models with these parameters \n",
    "    which can then be used to infer the parameters with the SBI package.\n",
    "\n",
    "    Input :\n",
    "    theta : torch tensor containing the parameters eta and s.\n",
    "\n",
    "    Output : \n",
    "    torch tensor containing the network simulations with parameter theta.\n",
    "    \"\"\"\n",
    "    num_sims = theta.shape[0] #number of simulations\n",
    "    res = []\n",
    "    if num_sims == 2:\n",
    "        cond = True #becomes false if the learning task is achieved\n",
    "        count = 0\n",
    "        while cond:\n",
    "            eta = theta.numpy()[0]\n",
    "            s = theta.numpy()[1]\n",
    "            nb_iter, times, accuracy = simulator_vectorized(eta, s, nb_obj_max=nb_obj_max)\n",
    "            #print(nb_iter)\n",
    "            if nb_iter < nb_obj_max + 1 :\n",
    "                cond = False\n",
    "            if count > 100:\n",
    "                print('count too big')\n",
    "                cond = False\n",
    "            count +=1\n",
    "        res.append(times)\n",
    "        #print(count)\n",
    "    else:\n",
    "        for n in range(num_sims):\n",
    "            cond = True #becomes false if the learning task is achieved\n",
    "            count = 0\n",
    "            while cond:\n",
    "                eta = theta.numpy()[n,0]\n",
    "                s = theta.numpy()[n,1]\n",
    "                nb_iter, times, accuracy = simulator_vectorized(eta, s, nb_obj_max=nb_obj_max)\n",
    "                if nb_iter < nb_obj_max + 1 :\n",
    "                    cond = False\n",
    "                if count > 100:\n",
    "                    print('count too big')\n",
    "                    cond = False\n",
    "                count +=1\n",
    "            res.append(times)\n",
    "    res = np.array(res)\n",
    "    return torch.FloatTensor(res)\n",
    "\n",
    "#parameters used to produce the synthetic data\n",
    "eta_0 = 1 \n",
    "s_0 = 0.15\n",
    "theta_0 = torch.tensor([eta_0,s_0])\n",
    "\n",
    "x_0 = simulator_sbi(theta_0) #synthetic data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the SBI method to get posteriors on the parameters eta and s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 2\n",
    "\n",
    "inference = SNPE_A(prior)\n",
    "proposal = prior\n",
    "for _ in range(num_rounds):\n",
    "    theta = proposal.sample((num_sims,))\n",
    "    x = simulator_sbi(theta)\n",
    "    _ = inference.append_simulations(theta, x, proposal=proposal).train()\n",
    "    posterior = inference.build_posterior().set_default_x(x_0)\n",
    "    proposal = posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save samples of the posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(posterior, f'/Users/sophiejaffard/Desktop/Expé/saves_sbi/posterior_{eta_inf}_{eta_sup}_{s_inf}_{s_sup}_{eta_0}_{s_0}.pt')\n",
    "posterior = torch.load(f'/Users/sophiejaffard/Desktop/Expé/saves_sbi/posterior_{eta_inf}_{eta_sup}_{s_inf}_{s_sup}_{eta_0}_{s_0}.pt')\n",
    "\n",
    "sample = posterior.sample((5000,))\n",
    "torch.save(sample, f'/Users/sophiejaffard/Desktop/Expé/saves_sbi/sample_{eta_inf}_{eta_sup}_{s_inf}_{s_sup}_{eta_0}_{s_0}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
